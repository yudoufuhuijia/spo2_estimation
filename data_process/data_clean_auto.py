"""
ä¿®å¤ç‰ˆæ•°æ®æ¸…æ´—è„šæœ¬ - è§£å†³æ¨¡ç³Šæ£€æµ‹è¯¯åˆ¤é—®é¢˜
æ”¹è¿›ï¼š
1. ç¦ç”¨åŸºäºLaplaciançš„æ¨¡ç³Šæ£€æµ‹ï¼ˆä¸é€‚ç”¨äºæ­¤æ•°æ®é›†ï¼‰
2. æ”¹ç”¨ç®€å•çš„å›¾ç‰‡æœ‰æ•ˆæ€§æ£€æµ‹ï¼ˆéå…¨é»‘ã€éå…¨ç™½ã€å°ºå¯¸æ­£å¸¸ï¼‰
3. ä¿ç•™å…¶ä»–æ¸…æ´—é€»è¾‘
"""

import oss2
import os
import numpy as np
import cv2
from config.oss_config import ACCESS_KEY_ID, ACCESS_KEY_SECRET, ENDPOINT, BUCKET_NAME
from utils.oss_file_reader import oss_read_file_stream, oss_write_log
import zipfile
import io
import tempfile
from datetime import datetime
from tqdm import tqdm
import pandas as pd
from multiprocessing import Pool, cpu_count
import traceback

# ===================== å…¨å±€é…ç½® =====================
class Config:
    PIS_OSS_DIR = "datasets/arpos/ARPOS/"
    VIPL_OSS_ROOT = "datasets/vipl/train/"

    OSS_CLEAN_LOG = "logs/clean_log.txt"
    OSS_VALID_INDEX = "processed_data/valid_data_index.csv"
    OSS_REPORT = "processed_data/cleaning_report.txt"

    # å›¾ç‰‡è´¨é‡æ£€æµ‹å‚æ•°
    MIN_IMAGE_SIZE = 50  # æœ€å°å›¾ç‰‡å°ºå¯¸ï¼ˆåƒç´ ï¼‰
    MIN_BRIGHTNESS = 5   # æœ€å°å¹³å‡äº®åº¦ï¼ˆ0-255ï¼‰
    MAX_BRIGHTNESS = 250 # æœ€å¤§å¹³å‡äº®åº¦ï¼ˆ0-255ï¼‰

    MIN_VIDEO_FRAMES = 30

    PIS_ZIP_PREFIX = "PIS"
    IMAGE_EXTENSIONS = (".png", ".jpg", ".jpeg")
    VIDEO_EXTENSIONS = (".mp4", ".avi")

    MAX_WORKERS = 2
    VIPL_SAMPLE_SIZE = 512 * 1024

# ===================== å·¥å…·å‡½æ•° =====================
def init_oss_bucket():
    auth = oss2.Auth(ACCESS_KEY_ID, ACCESS_KEY_SECRET)
    return oss2.Bucket(auth, ENDPOINT, BUCKET_NAME)

def is_image_valid(image):
    """
    æ”¹è¿›çš„å›¾ç‰‡æœ‰æ•ˆæ€§æ£€æµ‹
    ä¸ä½¿ç”¨Laplacianæ¨¡ç³Šæ£€æµ‹ï¼Œæ”¹ç”¨åŸºç¡€è´¨é‡æ£€æµ‹
    """
    try:
        # æ£€æŸ¥1: å°ºå¯¸æ˜¯å¦æ­£å¸¸
        h, w = image.shape[:2]
        if h < Config.MIN_IMAGE_SIZE or w < Config.MIN_IMAGE_SIZE:
            return False, "å°ºå¯¸è¿‡å°"

        # æ£€æŸ¥2: æ˜¯å¦å…¨é»‘æˆ–å…¨ç™½
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) if len(image.shape) == 3 else image
        mean_brightness = gray.mean()

        if mean_brightness < Config.MIN_BRIGHTNESS:
            return False, "å›¾ç‰‡è¿‡æš—ï¼ˆå¯èƒ½å…¨é»‘ï¼‰"

        if mean_brightness > Config.MAX_BRIGHTNESS:
            return False, "å›¾ç‰‡è¿‡äº®ï¼ˆå¯èƒ½å…¨ç™½ï¼‰"

        # æ£€æŸ¥3: æ˜¯å¦æœ‰å†…å®¹å˜åŒ–ï¼ˆæ ‡å‡†å·®>0ï¼‰
        std_brightness = gray.std()
        if std_brightness < 1.0:
            return False, "æ— å†…å®¹å˜åŒ–ï¼ˆçº¯è‰²å›¾ç‰‡ï¼‰"

        return True, "æœ‰æ•ˆ"

    except Exception as e:
        return False, f"æ£€æµ‹å¼‚å¸¸: {str(e)}"

def extract_label_from_path(file_path, data_type):
    try:
        if data_type == "PIS3252":
            # ç¤ºä¾‹: cropped-1-13-12-857.png
            # å€’æ•°ç¬¬äºŒä¸ªå­—æ®µæ˜¯æ ‡ç­¾
            parts = os.path.basename(file_path).split("-")
            if len(parts) >= 4:
                return parts[-2]
            return "unknown"
        elif data_type == "VIPL":
            parent_dir = os.path.basename(os.path.dirname(file_path))
            return parent_dir if parent_dir.isdigit() else "unknown"
    except:
        return "unknown"

def log_message(message, log_file=Config.OSS_CLEAN_LOG):
    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    log_line = f"[{timestamp}] {message}"
    print(log_line)
    try:
        oss_write_log(message, log_file)
    except:
        pass

# ===================== PISæ•°æ®å¤„ç† =====================
def process_single_pis_zip(args):
    zip_oss_path, bucket = args
    zip_basename = os.path.basename(zip_oss_path)
    valid_data = []
    stats = {
        "zip_name": zip_basename,
        "total_images": 0,
        "valid_images": 0,
        "too_small": 0,
        "too_dark": 0,
        "too_bright": 0,
        "no_variation": 0,
        "corrupted_images": 0,
        "errors": []
    }

    try:
        print(f"ğŸ“¦ æ­£åœ¨å¤„ç†: {zip_basename}")
        zip_data = b"".join(oss_read_file_stream(zip_oss_path))
        zip_stream = io.BytesIO(zip_data)

        with zipfile.ZipFile(zip_stream, 'r') as zip_file:
            all_files = zip_file.namelist()

            # æ™ºèƒ½æŸ¥æ‰¾å›¾ç‰‡æ–‡ä»¶
            image_files = []
            for f in all_files:
                if any(keyword in f for keyword in ["Color", "cheeksCombined", "AfterExcersizeCropped"]):
                    if f.lower().endswith(Config.IMAGE_EXTENSIONS):
                        image_files.append(f)

            if not image_files:
                image_files = [f for f in all_files if f.lower().endswith(Config.IMAGE_EXTENSIONS)]

            stats["total_images"] = len(image_files)

            if not image_files:
                stats["errors"].append("æœªæ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶")
                return valid_data, stats

            image_files.sort()

            for img_path in image_files:
                try:
                    img_binary = zip_file.read(img_path)
                    nparr = np.frombuffer(img_binary, np.uint8)
                    img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)

                    if img is None:
                        stats["corrupted_images"] += 1
                        continue

                    # ä½¿ç”¨æ–°çš„æœ‰æ•ˆæ€§æ£€æµ‹
                    is_valid, reason = is_image_valid(img)

                    if not is_valid:
                        # ç»Ÿè®¡å…·ä½“åŸå› 
                        if "å°ºå¯¸" in reason:
                            stats["too_small"] += 1
                        elif "è¿‡æš—" in reason:
                            stats["too_dark"] += 1
                        elif "è¿‡äº®" in reason:
                            stats["too_bright"] += 1
                        elif "æ— å†…å®¹" in reason:
                            stats["no_variation"] += 1
                        continue

                    label = extract_label_from_path(img_path, "PIS3252")

                    valid_data.append({
                        "data_type": "PIS3252",
                        "oss_path": zip_oss_path,
                        "inner_path": img_path,
                        "label": label,
                        "source_zip": zip_basename,
                        "image_shape": f"{img.shape[0]}x{img.shape[1]}"
                    })
                    stats["valid_images"] += 1

                except Exception as e:
                    stats["errors"].append(f"{img_path}: {str(e)}")

        print(f"âœ… {zip_basename}: {stats['valid_images']}/{stats['total_images']} å¼ æœ‰æ•ˆ")

    except Exception as e:
        error_msg = f"å‹ç¼©åŒ…å¤„ç†å¤±è´¥: {str(e)}"
        stats["errors"].append(error_msg)
        print(f"âŒ {zip_basename}: {error_msg}")

    return valid_data, stats

def clean_pis3252_data_parallel():
    bucket = init_oss_bucket()

    print(f"\nğŸ” æ‰«æOSSç›®å½•: {Config.PIS_OSS_DIR}")
    zip_files = []
    for obj in oss2.ObjectIterator(bucket, prefix=Config.PIS_OSS_DIR):
        file_name = obj.key
        if file_name.endswith(".zip") and Config.PIS_ZIP_PREFIX in os.path.basename(file_name):
            zip_files.append(file_name)

    total_zips = len(zip_files)
    print(f"ğŸ“Š å‘ç° {total_zips} ä¸ªPISå‹ç¼©åŒ…")
    log_message(f"å¼€å§‹æ‰¹é‡å¤„ç†PISæ•°æ® | æ€»å‹ç¼©åŒ…æ•°: {total_zips}")

    if total_zips == 0:
        print("âš ï¸  æœªæ‰¾åˆ°PISå‹ç¼©åŒ…")
        return [], []

    process_args = [(zip_path, bucket) for zip_path in zip_files]

    all_valid_data = []
    all_stats = []

    print("\nå¼€å§‹å¹¶è¡Œå¤„ç†...")
    with Pool(processes=Config.MAX_WORKERS) as pool:
        results = list(tqdm(
            pool.imap(process_single_pis_zip, process_args),
            total=total_zips,
            desc="å¤„ç†PISå‹ç¼©åŒ…",
            unit="ä¸ª"
        ))

    for valid_data, stats in results:
        all_valid_data.extend(valid_data)
        all_stats.append(stats)

    total_images = sum(s["total_images"] for s in all_stats)
    total_valid = sum(s["valid_images"] for s in all_stats)
    total_corrupted = sum(s["corrupted_images"] for s in all_stats)
    total_too_small = sum(s["too_small"] for s in all_stats)
    total_too_dark = sum(s["too_dark"] for s in all_stats)
    total_too_bright = sum(s["too_bright"] for s in all_stats)
    total_no_variation = sum(s["no_variation"] for s in all_stats)

    print(f"\nğŸ“ˆ PISæ•°æ®æ¸…æ´—å®Œæˆ:")
    print(f"   æ€»å›¾ç‰‡æ•°: {total_images}")
    print(f"   æœ‰æ•ˆå›¾ç‰‡: {total_valid} ({total_valid/total_images*100 if total_images > 0 else 0:.1f}%)")
    print(f"   è¿‡æ»¤è¯¦æƒ…:")
    print(f"     - æŸåå›¾ç‰‡: {total_corrupted}")
    print(f"     - å°ºå¯¸è¿‡å°: {total_too_small}")
    print(f"     - è¿‡æš—å›¾ç‰‡: {total_too_dark}")
    print(f"     - è¿‡äº®å›¾ç‰‡: {total_too_bright}")
    print(f"     - æ— å†…å®¹å˜åŒ–: {total_no_variation}")

    log_message(f"PISæ¸…æ´—å®Œæˆ | æœ‰æ•ˆ: {total_valid}/{total_images}")

    return all_valid_data, all_stats

# ===================== VIPLæ•°æ®å¤„ç† =====================
def process_single_vipl_video_lightweight(args):
    video_oss_path, bucket = args

    try:
        obj_meta = bucket.head_object(video_oss_path)
        file_size = obj_meta.content_length

        if file_size < 100 * 1024:
            return None, {"error": f"æ–‡ä»¶è¿‡å°({file_size} bytes)"}

        partial_data = b""
        for chunk in oss_read_file_stream(video_oss_path, chunk_size=Config.VIPL_SAMPLE_SIZE):
            partial_data += chunk
            if len(partial_data) >= Config.VIPL_SAMPLE_SIZE:
                break

        is_valid_video = (
            partial_data[:4] == b'RIFF' or
            b'ftyp' in partial_data[:32] or
            b'moov' in partial_data[:512]
        )

        if not is_valid_video:
            return None, {"error": "éæœ‰æ•ˆè§†é¢‘æ ¼å¼"}

        label = extract_label_from_path(video_oss_path, "VIPL")

        valid_data = {
            "data_type": "VIPL",
            "oss_path": video_oss_path,
            "inner_path": "",
            "label": label,
            "file_size": f"{file_size/(1024*1024):.2f}MB",
            "validated": "lightweight"
        }

        return valid_data, {"success": True}

    except Exception as e:
        return None, {"error": str(e)}

def clean_vipl_data_lightweight():
    bucket = init_oss_bucket()

    print(f"\nğŸ” æ‰«æVIPLè§†é¢‘: {Config.VIPL_OSS_ROOT}")
    video_files = []
    for obj in oss2.ObjectIterator(bucket, prefix=Config.VIPL_OSS_ROOT):
        if obj.key.lower().endswith(Config.VIDEO_EXTENSIONS):
            video_files.append(obj.key)

    total_videos = len(video_files)
    print(f"ğŸ“Š å‘ç° {total_videos} ä¸ªè§†é¢‘æ–‡ä»¶")
    print(f"âš¡ ä½¿ç”¨è½»é‡çº§éªŒè¯æ¨¡å¼")
    log_message(f"å¼€å§‹å¤„ç†VIPLæ•°æ® | æ€»è§†é¢‘æ•°: {total_videos}")

    if total_videos == 0:
        print("âš ï¸  æœªæ‰¾åˆ°VIPLè§†é¢‘")
        return [], []

    process_args = [(video_path, bucket) for video_path in video_files]

    valid_data = []
    error_count = 0

    print("\nå¼€å§‹å¤„ç†...")
    with Pool(processes=Config.MAX_WORKERS) as pool:
        results = list(tqdm(
            pool.imap(process_single_vipl_video_lightweight, process_args),
            total=total_videos,
            desc="éªŒè¯VIPLè§†é¢‘",
            unit="ä¸ª"
        ))

    for data, stats in results:
        if data:
            valid_data.append(data)
        else:
            error_count += 1

    print(f"\nğŸ“ˆ VIPLæ•°æ®æ¸…æ´—å®Œæˆ:")
    print(f"   æ€»è§†é¢‘æ•°: {total_videos}")
    print(f"   æœ‰æ•ˆè§†é¢‘: {len(valid_data)} ({len(valid_data)/total_videos*100 if total_videos > 0 else 0:.1f}%)")
    print(f"   æ— æ•ˆè§†é¢‘: {error_count}")

    log_message(f"VIPLæ¸…æ´—å®Œæˆ | æœ‰æ•ˆ: {len(valid_data)}/{total_videos}")

    return valid_data, []

# ===================== ç´¢å¼•ä¿å­˜ =====================
def save_valid_index(valid_data):
    if not valid_data:
        print("âš ï¸  æ²¡æœ‰æœ‰æ•ˆæ•°æ®")
        return None

    df = pd.DataFrame(valid_data)
    os.makedirs("tmp", exist_ok=True)
    local_csv = "tmp/valid_data_index.csv"
    df.to_csv(local_csv, index=False, encoding="utf-8")

    bucket = init_oss_bucket()
    bucket.put_object_from_file(Config.OSS_VALID_INDEX, local_csv)

    print(f"âœ… ç´¢å¼•æ–‡ä»¶å·²ä¿å­˜: {Config.OSS_VALID_INDEX}")
    log_message(f"ç´¢å¼•æ–‡ä»¶ç”Ÿæˆå®Œæˆ | æ€»è®°å½•æ•°: {len(df)}")

    os.remove(local_csv)
    return df

def generate_report(pis_stats, vipl_stats, total_valid):
    report_lines = [
        "=" * 60,
        "æ•°æ®æ¸…æ´—æŠ¥å‘Šï¼ˆä¿®å¤ç‰ˆï¼‰",
        "=" * 60,
        f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
        "",
        "ã€è´¨é‡æ£€æµ‹æ–¹æ³•ã€‘",
        "- ç¦ç”¨Laplacianæ¨¡ç³Šæ£€æµ‹ï¼ˆä¸é€‚ç”¨äºæ­¤æ•°æ®é›†ï¼‰",
        "- ä½¿ç”¨åŸºç¡€è´¨é‡æ£€æµ‹ï¼šå°ºå¯¸ã€äº®åº¦ã€å†…å®¹å˜åŒ–",
        "",
        "ã€PISæ•°æ®é›†ç»Ÿè®¡ã€‘",
        f"å¤„ç†å‹ç¼©åŒ…æ•°: {len(pis_stats)}",
    ]

    if pis_stats:
        total_pis_images = sum(s["total_images"] for s in pis_stats)
        total_pis_valid = sum(s["valid_images"] for s in pis_stats)
        total_corrupted = sum(s["corrupted_images"] for s in pis_stats)
        total_too_small = sum(s["too_small"] for s in pis_stats)
        total_too_dark = sum(s["too_dark"] for s in pis_stats)
        total_too_bright = sum(s["too_bright"] for s in pis_stats)
        total_no_variation = sum(s["no_variation"] for s in pis_stats)

        report_lines.extend([
            f"æ€»å›¾ç‰‡æ•°: {total_pis_images}",
            f"æœ‰æ•ˆå›¾ç‰‡: {total_pis_valid} ({total_pis_valid/total_pis_images*100 if total_pis_images > 0 else 0:.2f}%)",
            f"è¿‡æ»¤ç»Ÿè®¡:",
            f"  - æŸå: {total_corrupted}",
            f"  - å°ºå¯¸è¿‡å°: {total_too_small}",
            f"  - è¿‡æš—: {total_too_dark}",
            f"  - è¿‡äº®: {total_too_bright}",
            f"  - æ— å†…å®¹å˜åŒ–: {total_no_variation}",
            "",
            "å„å‹ç¼©åŒ…è¯¦æƒ…:",
        ])
        for s in pis_stats[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
            report_lines.append(
                f"  {s['zip_name']}: {s['valid_images']}/{s['total_images']}"
            )
        if len(pis_stats) > 10:
            report_lines.append(f"  ... å…±{len(pis_stats)}ä¸ªå‹ç¼©åŒ…")

    report_lines.extend([
        "",
        "ã€æœ€ç»ˆç»“æœã€‘",
        f"æ€»æœ‰æ•ˆæ•°æ®é‡: {total_valid}",
        f"ç´¢å¼•æ–‡ä»¶: {Config.OSS_VALID_INDEX}",
        "=" * 60
    ])

    report_text = "\n".join(report_lines)

    bucket = init_oss_bucket()
    bucket.put_object(Config.OSS_REPORT, report_text.encode('utf-8'))

    print(f"\nâœ… æ¸…æ´—æŠ¥å‘Šå·²ç”Ÿæˆ: {Config.OSS_REPORT}")
    print(report_text)

    return report_text

# ===================== ä¸»æµç¨‹ =====================
def main():
    print("=" * 60)
    print("ä¿®å¤ç‰ˆæ•°æ®æ¸…æ´—è„šæœ¬å¯åŠ¨")
    print("=" * 60)
    print("æ”¹è¿›: ç¦ç”¨ä¸é€‚ç”¨çš„æ¨¡ç³Šæ£€æµ‹ï¼Œä½¿ç”¨åŸºç¡€è´¨é‡æ£€æµ‹")
    print("=" * 60)

    start_time = datetime.now()
    log_message("===== æ•°æ®æ¸…æ´—ä»»åŠ¡å¼€å§‹ï¼ˆä¿®å¤ç‰ˆï¼‰=====")

    try:
        print("\nã€é˜¶æ®µ 1/3ã€‘å¤„ç†PISæ•°æ®é›†...")
        valid_pis, pis_stats = clean_pis3252_data_parallel()

        print("\nã€é˜¶æ®µ 2/3ã€‘å¤„ç†VIPLæ•°æ®é›†...")
        valid_vipl, vipl_stats = clean_vipl_data_lightweight()

        print("\nã€é˜¶æ®µ 3/3ã€‘ç”Ÿæˆæ•°æ®ç´¢å¼•...")
        all_valid = valid_pis + valid_vipl
        valid_df = save_valid_index(all_valid)

        total_valid = len(all_valid)
        generate_report(pis_stats, vipl_stats, total_valid)

        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()

        print("\n" + "=" * 60)
        print("ğŸ‰ æ•°æ®æ¸…æ´—å…¨éƒ¨å®Œæˆï¼")
        print("=" * 60)
        print(f"æ€»è€—æ—¶: {duration:.2f} ç§’")
        print(f"PISæœ‰æ•ˆæ•°æ®: {len(valid_pis)}")
        print(f"VIPLæœ‰æ•ˆæ•°æ®: {len(valid_vipl)}")
        print(f"æ€»æœ‰æ•ˆæ•°æ®: {total_valid}")
        print(f"ç´¢å¼•æ–‡ä»¶: {Config.OSS_VALID_INDEX}")
        print(f"æ¸…æ´—æŠ¥å‘Š: {Config.OSS_REPORT}")
        print("=" * 60)

        log_message(f"===== ä»»åŠ¡å®Œæˆ | æ€»è€—æ—¶: {duration:.2f}s | æœ‰æ•ˆæ•°æ®: {total_valid} =====")

        return True

    except Exception as e:
        error_msg = f"ä¸»æµç¨‹å¼‚å¸¸: {str(e)}\n{traceback.format_exc()}"
        log_message(error_msg)
        print(f"\nâŒ {error_msg}")
        return False

if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)